{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing data for feature engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_title</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>un día remix</td>\n",
       "      <td>you know that sometimes i think about us now a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>future nostalgia</td>\n",
       "      <td>future you want a timeless song i wanna change...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that kind of woman</td>\n",
       "      <td>one look was enough enough for me the whole ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if it aint me</td>\n",
       "      <td>i bet were higher than the people on cloud 9 t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>levitating remix</td>\n",
       "      <td>woohoo if you wanna run away with me i know a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           song_title                                             lyrics\n",
       "0        un día remix  you know that sometimes i think about us now a...\n",
       "1    future nostalgia  future you want a timeless song i wanna change...\n",
       "2  that kind of woman  one look was enough enough for me the whole ro...\n",
       "3       if it aint me  i bet were higher than the people on cloud 9 t...\n",
       "4    levitating remix  woohoo if you wanna run away with me i know a ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dualipa_df = pd.read_csv(\"dualipa.csv\", index_col=0)\n",
    "dualipa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_title</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eraser</td>\n",
       "      <td>i was born inside a small town i lost that sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bibia be ye ye</td>\n",
       "      <td>bibia be ye ye i lost my shoes last night i do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>save myself</td>\n",
       "      <td>i gave all my oxygen to people that could brea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nancy mulligan</td>\n",
       "      <td>i was twenty four years old when i met the wom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>perfect duet</td>\n",
       "      <td>i found a love for me oh darling just dive rig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       song_title                                             lyrics\n",
       "0          eraser  i was born inside a small town i lost that sta...\n",
       "1  bibia be ye ye  bibia be ye ye i lost my shoes last night i do...\n",
       "2     save myself  i gave all my oxygen to people that could brea...\n",
       "3  nancy mulligan  i was twenty four years old when i met the wom...\n",
       "4    perfect duet  i found a love for me oh darling just dive rig..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edsheeran_df = pd.read_csv(\"edsheeran.csv\", index_col=0)\n",
    "edsheeran_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 2) (88, 2)\n"
     ]
    }
   ],
   "source": [
    "print(dualipa_df.shape, edsheeran_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          song_title  \\\n",
      "0                       un día remix   \n",
      "4                   levitating remix   \n",
      "16                   new rules remix   \n",
      "17          that kind of woman remix   \n",
      "18              break my heart remix   \n",
      "19            kiss and make up remix   \n",
      "20           hallucinate remix remix   \n",
      "21                    physical remix   \n",
      "22            love is religion remix   \n",
      "23                 hallucinate remix   \n",
      "24  break my heart cosmic girl remix   \n",
      "25                  love again remix   \n",
      "26             don t start now remix   \n",
      "27           boys will be boys remix   \n",
      "28               pretty please remix   \n",
      "29            future nostalgia remix   \n",
      "30                        cool remix   \n",
      "31                 good in bed remix   \n",
      "50              blow your mind remix   \n",
      "56              dont start now remix   \n",
      "\n",
      "                                               lyrics  \n",
      "0   you know that sometimes i think about us now a...  \n",
      "4   woohoo if you wanna run away with me i know a ...  \n",
      "16  one one one one one talkin in my sleep at nigh...  \n",
      "17  stand back stand back stand back stand back st...  \n",
      "18  for sure i like falling for sure i like fallin...  \n",
      "19  future nostalgia kiss and make kiss kiss and m...  \n",
      "20  call my name call my name call my name call my...  \n",
      "21  caring about me now walk away you know how com...  \n",
      "22  i see the lights dancing dancing in your eyes ...  \n",
      "23  all the girls stomp your feet like this all th...  \n",
      "24  cosmic shes cosmic cosmic shes cosmic ooh i mu...  \n",
      "25  i never thought that i would find a way out i ...  \n",
      "26  bout me bout me bout me bout me bout me if you...  \n",
      "27  boys will be boys but girls will be women boys...  \n",
      "28  lief pretty lief pretty oh you look so pretty ...  \n",
      "29  hey this is dua lipa and youre listening to wi...  \n",
      "30  i guess were ready for the summer i like us be...  \n",
      "31  yeah lets get to the point here you love to di...  \n",
      "50  i know its hot i know weve got something that ...  \n",
      "56  bout me now bout me woo if you dont wanna see ...  \n",
      "                           song_title  \\\n",
      "5            how would you feel remix   \n",
      "12                   photograph remix   \n",
      "27                   wake me up remix   \n",
      "29                     the city remix   \n",
      "30  you need me i dont need you remix   \n",
      "31                         fall remix   \n",
      "32                     homeless remix   \n",
      "33                   the a team remix   \n",
      "37                      firefly remix   \n",
      "\n",
      "                                               lyrics  \n",
      "5   you are the one girl and you know that its tru...  \n",
      "12  loving can hurt loving can hurt sometimes but ...  \n",
      "27  on the last few days of la i got taken into th...  \n",
      "29  this city never sleeps i hear the people walk ...  \n",
      "30  now im in town break it down thinking of makin...  \n",
      "31  you and i two of a mind this loves one of a ki...  \n",
      "32  could i wake up next to you when were hitting ...  \n",
      "33  hello everyone yay were so near the time for e...  \n",
      "37  i fell in love next to you burning fires in th...  \n"
     ]
    }
   ],
   "source": [
    "# drop remix songs as the lyrics are more or less the same as the original\n",
    "\n",
    "print(dualipa_df[dualipa_df['song_title'].str.contains(\"remix\")])\n",
    "print(edsheeran_df[edsheeran_df['song_title'].str.contains(\"remix\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 2)\n",
      "(79, 2)\n"
     ]
    }
   ],
   "source": [
    "# dropping remixes\n",
    "dualipa_remix = dualipa_df[dualipa_df['song_title'].str.contains(\"remix\")]\n",
    "dualipa_df.drop(dualipa_remix.index, inplace=True)\n",
    "print(dualipa_df.shape)\n",
    "\n",
    "edsheeran_remix = edsheeran_df[edsheeran_df['song_title'].str.contains(\"remix\")]\n",
    "edsheeran_df.drop(edsheeran_remix.index, inplace=True)\n",
    "print(edsheeran_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dont</td>\n",
       "      <td>i met this girl late last year she said dont y...</td>\n",
       "      <td>ed_sheeran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cool</td>\n",
       "      <td>guess i never had a love like this hit me hard...</td>\n",
       "      <td>dua_lipa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000 nights</td>\n",
       "      <td>oh i been on for a thousand nights new york to...</td>\n",
       "      <td>ed_sheeran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>even my dad does sometimes</td>\n",
       "      <td>its alright to cry even my dad does sometimes ...</td>\n",
       "      <td>ed_sheeran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i dont want your money</td>\n",
       "      <td>ayy i waited for you all day i been away on th...</td>\n",
       "      <td>ed_sheeran</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   song_title  \\\n",
       "0                        dont   \n",
       "1                        cool   \n",
       "2                 1000 nights   \n",
       "3  even my dad does sometimes   \n",
       "4      i dont want your money   \n",
       "\n",
       "                                              lyrics       label  \n",
       "0  i met this girl late last year she said dont y...  ed_sheeran  \n",
       "1  guess i never had a love like this hit me hard...    dua_lipa  \n",
       "2  oh i been on for a thousand nights new york to...  ed_sheeran  \n",
       "3  its alright to cry even my dad does sometimes ...  ed_sheeran  \n",
       "4  ayy i waited for you all day i been away on th...  ed_sheeran  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding an artist label and combining both dataframes and shuffling\n",
    "\n",
    "dualipa_df['label'] = 'dua_lipa'\n",
    "edsheeran_df['label'] = 'ed_sheeran'\n",
    "\n",
    "data = pd.concat([dualipa_df, edsheeran_df], ignore_index=True, axis=0)\n",
    "\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Adding text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding simple features such as character count, word count and average word length\n",
    "\n",
    "#adding character count\n",
    "data['char_count'] = data['lyrics'].apply(len)\n",
    "\n",
    "#adding word count\n",
    "def word_counter(text):\n",
    "    words = text.split()\n",
    "    return (len(words))\n",
    "\n",
    "data['word_count'] = data['lyrics'].apply(word_counter)\n",
    "\n",
    "#adding average word length\n",
    "def avg_word_len(text):\n",
    "    words = text.split()\n",
    "    words_lens = [len(word) for word in words]\n",
    "    return (np.mean(words_lens))\n",
    "\n",
    "data['avg_word_len'] = data['lyrics'].apply(avg_word_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>label</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dont</td>\n",
       "      <td>i met this girl late last year she said dont y...</td>\n",
       "      <td>ed_sheeran</td>\n",
       "      <td>2786</td>\n",
       "      <td>594</td>\n",
       "      <td>3.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cool</td>\n",
       "      <td>guess i never had a love like this hit me hard...</td>\n",
       "      <td>dua_lipa</td>\n",
       "      <td>1862</td>\n",
       "      <td>414</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000 nights</td>\n",
       "      <td>oh i been on for a thousand nights new york to...</td>\n",
       "      <td>ed_sheeran</td>\n",
       "      <td>3092</td>\n",
       "      <td>649</td>\n",
       "      <td>3.765794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>even my dad does sometimes</td>\n",
       "      <td>its alright to cry even my dad does sometimes ...</td>\n",
       "      <td>ed_sheeran</td>\n",
       "      <td>747</td>\n",
       "      <td>159</td>\n",
       "      <td>3.704403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i dont want your money</td>\n",
       "      <td>ayy i waited for you all day i been away on th...</td>\n",
       "      <td>ed_sheeran</td>\n",
       "      <td>2033</td>\n",
       "      <td>449</td>\n",
       "      <td>3.530067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   song_title  \\\n",
       "0                        dont   \n",
       "1                        cool   \n",
       "2                 1000 nights   \n",
       "3  even my dad does sometimes   \n",
       "4      i dont want your money   \n",
       "\n",
       "                                              lyrics       label  char_count  \\\n",
       "0  i met this girl late last year she said dont y...  ed_sheeran        2786   \n",
       "1  guess i never had a love like this hit me hard...    dua_lipa        1862   \n",
       "2  oh i been on for a thousand nights new york to...  ed_sheeran        3092   \n",
       "3  its alright to cry even my dad does sometimes ...  ed_sheeran         747   \n",
       "4  ayy i waited for you all day i been away on th...  ed_sheeran        2033   \n",
       "\n",
       "   word_count  avg_word_len  \n",
       "0         594      3.691919  \n",
       "1         414      3.500000  \n",
       "2         649      3.765794  \n",
       "3         159      3.704403  \n",
       "4         449      3.530067  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['common', 'love', 'is', 'nt', 'for', 'us', 'we', 'created', 'something', 'phenomenal', 'do', 'nt', 'you', 'agree', 'do', 'nt', 'you', 'agree', 'you', 'got', 'me', 'feeling', 'diamond', 'rich', 'nothing', 'on', 'this', 'planet', 'compares', 'to', 'it', 'do', 'nt', 'you', 'agree', 'dontyouagree', 'who', 'needs', 'togo', 'to', 'sleep', 'when', 'i', 'gotyou', 'next', 'to', 'me', 'all', 'night', 'ill', 'riot', 'with', 'you', 'i', 'know', 'you', 'got', 'my', 'back', 'and', 'you', 'know', 'i', 'got', 'you', 'so', 'come', 'on', 'come', 'on', 'come', 'on', 'lets', 'get', 'physical', 'lights', 'out', 'follow', 'the', 'noise', 'baby', 'keep', 'on', 'dancing', 'like', 'you', 'ai', 'nt', 'got', 'a', 'choice', 'so', 'come', 'on', 'come', 'on', 'come', 'on', 'lets', 'get', 'physical', 'adrenaline', 'keeps', 'on', 'rushing', 'in', 'love', 'the', 'simulation', 'were', 'dreaming', 'in', 'do', 'nt', 'you', 'agree', 'do', 'nt', 'you', 'agree', 'i', 'do', 'nt', 'wanna', 'live', 'another', 'life', 'cause', 'this', 'ones', 'pretty', 'nice', 'living', 'it', 'up', 'who', 'needs', 'to', 'go', 'to', 'sleep', 'when', 'i', 'got', 'you', 'next', 'to', 'me', 'all', 'night', 'ill', 'riot', 'with', 'you', 'i', 'know', 'you', 'got', 'my', 'back', 'and', 'you', 'know', 'i', 'got', 'you', 'so', 'come', 'on', 'come', 'on', 'come', 'on', 'lets', 'get', 'physical', 'lights', 'out', 'follow', 'the', 'noise', 'baby', 'keep', 'on', 'dancing', 'like', 'you', 'ai', 'nt', 'got', 'a', 'choice', 'so', 'come', 'on', 'come', 'on', 'come', 'on', 'lets', 'get', 'physical', 'hold', 'on', 'just', 'a', 'little', 'tighter', 'come', 'on', 'hold', 'on', 'tell', 'me', 'if', 'you', 're', 'ready', 'come', 'on', 'baby', 'keep', 'on', 'dancing', 'lets', 'get', 'physical', 'hold', 'on', 'just', 'a', 'little', 'tighter', 'come', 'on', 'hold', 'on', 'tell', 'me', 'if', 'you', 're', 'ready', 'come', 'on', 'baby', 'keep', 'on', 'dancing', 'lets', 'get', 'physical', 'all', 'night', 'ill', 'riot', 'with', 'you', 'i', 'know', 'you', 'got', 'my', 'back', 'and', 'you', 'know', 'i', 'got', 'you', 'so', 'come', 'on', 'come', 'on', 'come', 'on', 'lets', 'get', 'physical', 'lights', 'out', 'follow', 'the', 'noise', 'baby', 'keep', 'on', 'dancing', 'like', 'you', 'ai', 'nt', 'got', 'a', 'choice', 'so', 'come', 'on', 'come', 'on', 'come', 'on', 'lets', 'get', 'physical', 'lets', 'get', 'physical', 'physical', 'lets', 'get', 'physical', 'come', 'on', 'phy', 'phy', 'phy', 'physical']\n",
      "[('common', 'ADJ'), ('love', 'NOUN'), ('is', 'AUX'), ('nt', 'PART'), ('for', 'ADP'), ('us', 'PRON'), ('we', 'PRON'), ('created', 'VERB'), ('something', 'PRON'), ('phenomenal', 'ADJ'), ('do', 'AUX'), ('nt', 'AUX'), ('you', 'PRON'), ('agree', 'VERB'), ('do', 'AUX'), ('nt', 'PART'), ('you', 'PRON'), ('agree', 'VERB'), ('you', 'PRON'), ('got', 'VERB'), ('me', 'PRON'), ('feeling', 'VERB'), ('diamond', 'NOUN'), ('rich', 'ADJ'), ('nothing', 'PRON'), ('on', 'ADP'), ('this', 'DET'), ('planet', 'NOUN'), ('compares', 'VERB'), ('to', 'ADP'), ('it', 'PRON'), ('do', 'AUX'), ('nt', 'PART'), ('you', 'PRON'), ('agree', 'VERB'), ('dontyouagree', 'NOUN'), ('who', 'PRON'), ('needs', 'VERB'), ('togo', 'NOUN'), ('to', 'PART'), ('sleep', 'VERB'), ('when', 'ADV'), ('i', 'PRON'), ('gotyou', 'VERB'), ('next', 'ADV'), ('to', 'ADP'), ('me', 'PRON'), ('all', 'DET'), ('night', 'NOUN'), ('ill', 'ADJ'), ('riot', 'NOUN'), ('with', 'ADP'), ('you', 'PRON'), ('i', 'PRON'), ('know', 'VERB'), ('you', 'PRON'), ('got', 'VERB'), ('my', 'PRON'), ('back', 'NOUN'), ('and', 'CCONJ'), ('you', 'PRON'), ('know', 'VERB'), ('i', 'PRON'), ('got', 'VERB'), ('you', 'PRON'), ('so', 'ADV'), ('come', 'VERB'), ('on', 'ADP'), ('come', 'VERB'), ('on', 'ADP'), ('come', 'NOUN'), ('on', 'ADP'), ('lets', 'NOUN'), ('get', 'VERB'), ('physical', 'ADJ'), ('lights', 'NOUN'), ('out', 'ADP'), ('follow', 'VERB'), ('the', 'DET'), ('noise', 'NOUN'), ('baby', 'NOUN'), ('keep', 'VERB'), ('on', 'ADP'), ('dancing', 'VERB'), ('like', 'ADP'), ('you', 'PRON'), ('ai', 'AUX'), ('nt', 'PART'), ('got', 'VERB'), ('a', 'DET'), ('choice', 'NOUN'), ('so', 'ADV'), ('come', 'VERB'), ('on', 'ADP'), ('come', 'VERB'), ('on', 'ADP'), ('come', 'NOUN'), ('on', 'ADP'), ('lets', 'NOUN'), ('get', 'VERB'), ('physical', 'ADJ'), ('adrenaline', 'NOUN'), ('keeps', 'VERB'), ('on', 'ADP'), ('rushing', 'VERB'), ('in', 'ADP'), ('love', 'NOUN'), ('the', 'DET'), ('simulation', 'NOUN'), ('were', 'AUX'), ('dreaming', 'VERB'), ('in', 'ADP'), ('do', 'AUX'), ('nt', 'PART'), ('you', 'PRON'), ('agree', 'VERB'), ('do', 'AUX'), ('nt', 'PART'), ('you', 'PRON'), ('agree', 'VERB'), ('i', 'PRON'), ('do', 'AUX'), ('nt', 'PART'), ('wanna', 'VERB'), ('live', 'VERB'), ('another', 'DET'), ('life', 'NOUN'), ('cause', 'VERB'), ('this', 'DET'), ('ones', 'NOUN'), ('pretty', 'ADV'), ('nice', 'ADJ'), ('living', 'VERB'), ('it', 'PRON'), ('up', 'ADP'), ('who', 'PRON'), ('needs', 'VERB'), ('to', 'PART'), ('go', 'VERB'), ('to', 'ADP'), ('sleep', 'NOUN'), ('when', 'ADV'), ('i', 'PRON'), ('got', 'VERB'), ('you', 'PRON'), ('next', 'ADJ'), ('to', 'ADP'), ('me', 'PRON'), ('all', 'DET'), ('night', 'NOUN'), ('ill', 'ADJ'), ('riot', 'NOUN'), ('with', 'ADP'), ('you', 'PRON'), ('i', 'PRON'), ('know', 'VERB'), ('you', 'PRON'), ('got', 'VERB'), ('my', 'PRON'), ('back', 'NOUN'), ('and', 'CCONJ'), ('you', 'PRON'), ('know', 'VERB'), ('i', 'PRON'), ('got', 'VERB'), ('you', 'PRON'), ('so', 'ADV'), ('come', 'VERB'), ('on', 'ADP'), ('come', 'VERB'), ('on', 'ADP'), ('come', 'NOUN'), ('on', 'ADP'), ('lets', 'NOUN'), ('get', 'VERB'), ('physical', 'ADJ'), ('lights', 'NOUN'), ('out', 'ADP'), ('follow', 'VERB'), ('the', 'DET'), ('noise', 'NOUN'), ('baby', 'NOUN'), ('keep', 'VERB'), ('on', 'ADP'), ('dancing', 'VERB'), ('like', 'ADP'), ('you', 'PRON'), ('ai', 'AUX'), ('nt', 'PART'), ('got', 'VERB'), ('a', 'DET'), ('choice', 'NOUN'), ('so', 'ADV'), ('come', 'VERB'), ('on', 'ADP'), ('come', 'VERB'), ('on', 'ADP'), ('come', 'NOUN'), ('on', 'ADP'), ('lets', 'NOUN'), ('get', 'VERB'), ('physical', 'ADJ'), ('hold', 'NOUN'), ('on', 'ADP'), ('just', 'ADV'), ('a', 'DET'), ('little', 'ADJ'), ('tighter', 'ADJ'), ('come', 'VERB'), ('on', 'ADP'), ('hold', 'NOUN'), ('on', 'ADP'), ('tell', 'VERB'), ('me', 'PRON'), ('if', 'SCONJ'), ('you', 'PRON'), ('re', 'VERB'), ('ready', 'ADJ'), ('come', 'VERB'), ('on', 'ADP'), ('baby', 'NOUN'), ('keep', 'VERB'), ('on', 'ADP'), ('dancing', 'VERB'), ('lets', 'NOUN'), ('get', 'VERB'), ('physical', 'ADJ'), ('hold', 'NOUN'), ('on', 'ADP'), ('just', 'ADV'), ('a', 'DET'), ('little', 'ADJ'), ('tighter', 'ADJ'), ('come', 'VERB'), ('on', 'ADP'), ('hold', 'NOUN'), ('on', 'ADP'), ('tell', 'VERB'), ('me', 'PRON'), ('if', 'SCONJ'), ('you', 'PRON'), ('re', 'VERB'), ('ready', 'ADJ'), ('come', 'VERB'), ('on', 'ADP'), ('baby', 'NOUN'), ('keep', 'VERB'), ('on', 'ADP'), ('dancing', 'VERB'), ('lets', 'NOUN'), ('get', 'VERB'), ('physical', 'ADJ'), ('all', 'DET'), ('night', 'NOUN'), ('ill', 'ADJ'), ('riot', 'NOUN'), ('with', 'ADP'), ('you', 'PRON'), ('i', 'PRON'), ('know', 'VERB'), ('you', 'PRON'), ('got', 'VERB'), ('my', 'PRON'), ('back', 'NOUN'), ('and', 'CCONJ'), ('you', 'PRON'), ('know', 'VERB'), ('i', 'PRON'), ('got', 'VERB'), ('you', 'PRON'), ('so', 'ADV'), ('come', 'VERB'), ('on', 'ADP'), ('come', 'VERB'), ('on', 'ADP'), ('come', 'NOUN'), ('on', 'ADP'), ('lets', 'NOUN'), ('get', 'VERB'), ('physical', 'ADJ'), ('lights', 'NOUN'), ('out', 'ADP'), ('follow', 'VERB'), ('the', 'DET'), ('noise', 'NOUN'), ('baby', 'NOUN'), ('keep', 'VERB'), ('on', 'ADP'), ('dancing', 'VERB'), ('like', 'ADP'), ('you', 'PRON'), ('ai', 'AUX'), ('nt', 'PART'), ('got', 'VERB'), ('a', 'DET'), ('choice', 'NOUN'), ('so', 'ADV'), ('come', 'VERB'), ('on', 'ADP'), ('come', 'VERB'), ('on', 'ADP'), ('come', 'NOUN'), ('on', 'ADP'), ('lets', 'NOUN'), ('get', 'VERB'), ('physical', 'ADJ'), ('lets', 'NOUN'), ('get', 'VERB'), ('physical', 'ADJ'), ('physical', 'ADJ'), ('lets', 'NOUN'), ('get', 'VERB'), ('physical', 'ADJ'), ('come', 'VERB'), ('on', 'ADP'), ('phy', 'NOUN'), ('phy', 'NOUN'), ('phy', 'NOUN'), ('physical', 'ADJ')]\n"
     ]
    }
   ],
   "source": [
    "# tokenizing and lemmatizing text \n",
    "# Load the en_core_web_sm model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "example = data.loc[data['song_title']=='physical', 'lyrics'].values[0]\n",
    "\n",
    "# Create a Doc object\n",
    "doc = nlp(example)\n",
    "\n",
    "# Generate the tokens\n",
    "tokens = [token.text for token in doc]\n",
    "print(tokens)\n",
    "\n",
    "# Generate tokens and pos tags\n",
    "pos = [(token.text, token.pos_) for token in doc]\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>label</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>pronoun_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dont</td>\n",
       "      <td>i met this girl late last year she said dont y...</td>\n",
       "      <td>ed_sheeran</td>\n",
       "      <td>2786</td>\n",
       "      <td>594</td>\n",
       "      <td>3.691919</td>\n",
       "      <td>107</td>\n",
       "      <td>96</td>\n",
       "      <td>18</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cool</td>\n",
       "      <td>guess i never had a love like this hit me hard...</td>\n",
       "      <td>dua_lipa</td>\n",
       "      <td>1862</td>\n",
       "      <td>414</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>88</td>\n",
       "      <td>55</td>\n",
       "      <td>33</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000 nights</td>\n",
       "      <td>oh i been on for a thousand nights new york to...</td>\n",
       "      <td>ed_sheeran</td>\n",
       "      <td>3092</td>\n",
       "      <td>649</td>\n",
       "      <td>3.765794</td>\n",
       "      <td>91</td>\n",
       "      <td>147</td>\n",
       "      <td>40</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>even my dad does sometimes</td>\n",
       "      <td>its alright to cry even my dad does sometimes ...</td>\n",
       "      <td>ed_sheeran</td>\n",
       "      <td>747</td>\n",
       "      <td>159</td>\n",
       "      <td>3.704403</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i dont want your money</td>\n",
       "      <td>ayy i waited for you all day i been away on th...</td>\n",
       "      <td>ed_sheeran</td>\n",
       "      <td>2033</td>\n",
       "      <td>449</td>\n",
       "      <td>3.530067</td>\n",
       "      <td>87</td>\n",
       "      <td>85</td>\n",
       "      <td>20</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   song_title  \\\n",
       "0                        dont   \n",
       "1                        cool   \n",
       "2                 1000 nights   \n",
       "3  even my dad does sometimes   \n",
       "4      i dont want your money   \n",
       "\n",
       "                                              lyrics       label  char_count  \\\n",
       "0  i met this girl late last year she said dont y...  ed_sheeran        2786   \n",
       "1  guess i never had a love like this hit me hard...    dua_lipa        1862   \n",
       "2  oh i been on for a thousand nights new york to...  ed_sheeran        3092   \n",
       "3  its alright to cry even my dad does sometimes ...  ed_sheeran         747   \n",
       "4  ayy i waited for you all day i been away on th...  ed_sheeran        2033   \n",
       "\n",
       "   word_count  avg_word_len  verb_count  noun_count  adj_count  pronoun_count  \n",
       "0         594      3.691919         107          96         18            116  \n",
       "1         414      3.500000          88          55         33            117  \n",
       "2         649      3.765794          91         147         40             90  \n",
       "3         159      3.704403          32          22          6             26  \n",
       "4         449      3.530067          87          85         20            111  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating functions to return the numbers of different Part of Speech tags\n",
    "\n",
    "def verb_counter(text, model=nlp):\n",
    "    doc = model(text)\n",
    "    pos = [token.pos_ for token in doc]\n",
    "    return pos.count('VERB')\n",
    "\n",
    "def noun_counter(text, model=nlp):\n",
    "    doc = model(text)\n",
    "    pos = [token.pos_ for token in doc]\n",
    "    return pos.count('NOUN')\n",
    "\n",
    "def adj_counter(text, model=nlp):\n",
    "    doc = model(text)\n",
    "    pos = [token.pos_ for token in doc]\n",
    "    return pos.count('ADJ')\n",
    "\n",
    "def pronoun_counter(text, model=nlp):\n",
    "    doc = model(text)\n",
    "    pos = [token.pos_ for token in doc]\n",
    "    return pos.count('PRON')\n",
    "\n",
    "data['verb_count'] = data['lyrics'].apply(verb_counter)\n",
    "data['noun_count'] = data['lyrics'].apply(noun_counter)\n",
    "data['adj_count'] = data['lyrics'].apply(adj_counter)\n",
    "data['pronoun_count'] = data['lyrics'].apply(pronoun_counter)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common love be nt for we we create something phenomenal do nt you agree do nt you agree you get I feel diamond rich nothing on this planet compare to it do nt you agree dontyouagree who need togo to sleep when I gotyou next to I all night ill riot with you I know you get my back and you know I get you so come on come on come on let get physical light out follow the noise baby keep on dance like you ai nt get a choice so come on come on come on let get physical adrenaline keep on rush in love the simulation be dream in do nt you agree do nt you agree I do nt wanna live another life cause this one pretty nice live it up who need to go to sleep when I get you next to I all night ill riot with you I know you get my back and you know I get you so come on come on come on let get physical light out follow the noise baby keep on dance like you ai nt get a choice so come on come on come on let get physical hold on just a little tight come on hold on tell I if you re ready come on baby keep on dance let get physical hold on just a little tight come on hold on tell I if you re ready come on baby keep on dance let get physical all night ill riot with you I know you get my back and you know I get you so come on come on come on let get physical light out follow the noise baby keep on dance like you ai nt get a choice so come on come on come on let get physical let get physical physical let get physical come on phy phy phy physical\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "lemmas = [token.lemma_ for token in doc]\n",
    "print(print(' '.join(lemmas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common love create phenomenal agree agree I feel diamond rich planet compare agree dontyouagree need togo sleep I gotyou I night riot I know know I come come come let physical light follow noise baby dance like choice come come come let physical adrenaline rush love simulation dream agree agree I wanna live life cause pretty nice live need sleep I I night riot I know know I come come come let physical light follow noise baby dance like choice come come come let physical hold little tight come hold tell I ready come baby dance let physical hold little tight come hold tell I ready come baby dance let physical night riot I know know I come come come let physical light follow noise baby dance like choice come come come let physical let physical physical let physical come phy phy phy physical\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "stopwords.update(['ill', 'nt', 're', 'ai', 've'])\n",
    "\n",
    "clean_lemmas = [lemma for lemma in lemmas if lemma.isalpha() and lemma not in stopwords]\n",
    "print(print(' '.join(clean_lemmas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>label</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>pronoun_count</th>\n",
       "      <th>lemm_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dont</td>\n",
       "      <td>i met this girl late last year she said dont y...</td>\n",
       "      <td>ed_sheeran</td>\n",
       "      <td>2786</td>\n",
       "      <td>594</td>\n",
       "      <td>3.691919</td>\n",
       "      <td>107</td>\n",
       "      <td>96</td>\n",
       "      <td>18</td>\n",
       "      <td>116</td>\n",
       "      <td>I meet girl late year worry I disappear I tell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cool</td>\n",
       "      <td>guess i never had a love like this hit me hard...</td>\n",
       "      <td>dua_lipa</td>\n",
       "      <td>1862</td>\n",
       "      <td>414</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>88</td>\n",
       "      <td>55</td>\n",
       "      <td>33</td>\n",
       "      <td>117</td>\n",
       "      <td>guess I love like hit I hard I expect goddamn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000 nights</td>\n",
       "      <td>oh i been on for a thousand nights new york to...</td>\n",
       "      <td>ed_sheeran</td>\n",
       "      <td>3092</td>\n",
       "      <td>649</td>\n",
       "      <td>3.765794</td>\n",
       "      <td>91</td>\n",
       "      <td>147</td>\n",
       "      <td>40</td>\n",
       "      <td>90</td>\n",
       "      <td>oh I thousand night new york london different ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>even my dad does sometimes</td>\n",
       "      <td>its alright to cry even my dad does sometimes ...</td>\n",
       "      <td>ed_sheeran</td>\n",
       "      <td>747</td>\n",
       "      <td>159</td>\n",
       "      <td>3.704403</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>alright cry dad wipe eye tear remind alive alr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i dont want your money</td>\n",
       "      <td>ayy i waited for you all day i been away on th...</td>\n",
       "      <td>ed_sheeran</td>\n",
       "      <td>2033</td>\n",
       "      <td>449</td>\n",
       "      <td>3.530067</td>\n",
       "      <td>87</td>\n",
       "      <td>85</td>\n",
       "      <td>20</td>\n",
       "      <td>111</td>\n",
       "      <td>ayy I wait day I away road little today I m he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   song_title  \\\n",
       "0                        dont   \n",
       "1                        cool   \n",
       "2                 1000 nights   \n",
       "3  even my dad does sometimes   \n",
       "4      i dont want your money   \n",
       "\n",
       "                                              lyrics       label  char_count  \\\n",
       "0  i met this girl late last year she said dont y...  ed_sheeran        2786   \n",
       "1  guess i never had a love like this hit me hard...    dua_lipa        1862   \n",
       "2  oh i been on for a thousand nights new york to...  ed_sheeran        3092   \n",
       "3  its alright to cry even my dad does sometimes ...  ed_sheeran         747   \n",
       "4  ayy i waited for you all day i been away on th...  ed_sheeran        2033   \n",
       "\n",
       "   word_count  avg_word_len  verb_count  noun_count  adj_count  pronoun_count  \\\n",
       "0         594      3.691919         107          96         18            116   \n",
       "1         414      3.500000          88          55         33            117   \n",
       "2         649      3.765794          91         147         40             90   \n",
       "3         159      3.704403          32          22          6             26   \n",
       "4         449      3.530067          87          85         20            111   \n",
       "\n",
       "                                         lemm_lyrics  \n",
       "0  I meet girl late year worry I disappear I tell...  \n",
       "1  guess I love like hit I hard I expect goddamn ...  \n",
       "2  oh I thousand night new york london different ...  \n",
       "3  alright cry dad wipe eye tear remind alive alr...  \n",
       "4  ayy I wait day I away road little today I m he...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying lemmatization on the whole data\n",
    "\n",
    "def preprocess(text):\n",
    "    # Create doc object\n",
    "    doc = nlp(text)\n",
    "    # Generate lemmas\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    # Remove stopwords and non-alphabetic characters\n",
    "    clean_lemmas = [lemma for lemma in lemmas \n",
    "                    if lemma.isalpha() and lemma not in stopwords]\n",
    "    \n",
    "    return ' '.join(clean_lemmas)\n",
    "  \n",
    "\n",
    "data['lemm_lyrics'] = data['lyrics'].apply(preprocess)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to training and testing\n",
    "\n",
    "X = data.drop(['label', 'lyrics'], axis=1)\n",
    "\n",
    "y = data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 2864)\n",
      "(36, 2864)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform X_train\n",
    "X_train_bow = vectorizer.fit_transform(X_train['lyrics'])\n",
    "\n",
    "# Transform X_test\n",
    "X_test_bow = vectorizer.transform(X_test['lyrics'])\n",
    "\n",
    "# Print shape of X_train_bow and X_test_bow\n",
    "print(X_train_bow.shape)\n",
    "print(X_test_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the classifier on the test set is 0.694\n"
     ]
    }
   ],
   "source": [
    "# build a naiive bias model using only BoW vectorization of lemmatized lyrics\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Fit the classifier\n",
    "clf.fit(X_train_bow, y_train)\n",
    "\n",
    "# Measure the accuracy\n",
    "accuracy = clf.score(X_test_bow, y_test)\n",
    "print(\"The accuracy of the classifier on the test set is %.3f\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('text',\n",
       "                                                  CountVectorizer(stop_words='english'),\n",
       "                                                  'lyrics')])),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can do this also using pipeline and include the other features\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "        ('text', CountVectorizer(stop_words='english'), 'lyrics')])\n",
    "                                 \n",
    "pipeline = Pipeline([\n",
    "     ('preprocessor', preprocessor),\n",
    "     ('clf', MultinomialNB())])\n",
    "\n",
    "pipeline.fit(X_train, y_train)                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6944444444444444"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    dua_lipa       0.55      0.50      0.52        12\n",
      "  ed_sheeran       0.76      0.79      0.78        24\n",
      "\n",
      "    accuracy                           0.69        36\n",
      "   macro avg       0.65      0.65      0.65        36\n",
      "weighted avg       0.69      0.69      0.69        36\n",
      "\n",
      "0.6944444444444444\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  6]\n",
      " [ 5 19]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7826086956521741"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(pipeline, X, y, cv=5, n_jobs=-1)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6637681159420289"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also try with tfidf vectorizer instead of count vectorizer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "        ('text', TfidfVectorizer(stop_words='english'), 'lyrics')])\n",
    "                                 \n",
    "pipeline = Pipeline([\n",
    "     ('preprocessor', preprocessor),\n",
    "     ('clf', MultinomialNB())])\n",
    "\n",
    "scores = cross_val_score(pipeline, X, y, cv=5, n_jobs=-1)\n",
    "scores.mean()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
